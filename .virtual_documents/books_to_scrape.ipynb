import requests
from bs4 import BeautifulSoup
import pandas as pd
from urllib.parse import urljoin


url = "https://books.toscrape.com/"
books_list = []
page = 1


while url:
    r = requests.get(url)
    r.encoding = "utf-8"
    print(f'Processing Page {page}- {url}')
    soup = BeautifulSoup(r.text, "html.parser")
    books = soup.find_all("article", class_ = "product_pod")
    for book in books:
        title = book.select_one("h3 a")["title"]
        price = book.select_one(".price_color").text.strip().replace("Â£", "")
        rating = book.select_one(".star-rating")["class"][1]

        books_list.append({
            "Title": title,
            "Price": price,
            "Rating": rating,
            "Page": page
        })
        
    #Find Next Page
    next_btn = soup.find("li", class_="next")

    if next_btn:
        next_link = next_btn.a["href"]
        url = urljoin(url, next_link)
        page += 1
    else:
        url = None

        
print("Total Books:", len(books_list))


data = pd.DataFrame(books_list)


data.head()


data.to_csv("books.csv", index=False)


data.groupby('Rating')['Title']



