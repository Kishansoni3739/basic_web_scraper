import requests
from bs4 import BeautifulSoup
import pandas as pd


base_url = "https://quotes.toscrape.com/page/{}/"
quotes_list = []
for page in range(1, 6):
    url = base_url.format(page)
    print("Scrapping from", url)

    response = requests.get(url)
    soup = BeautifulSoup(response.text,"html.parser")

    quotes = soup.find_all("div", class_="quote")
    
    for q in quotes:
        quote = q.find("span", class_="text").text
        author = q.find("small", class_="author").text
    
        quotes_list.append({
            "Quote": quote,
            "Author": author,
            "Page": page
        })

print(quotes_list)


data = pd.DataFrame(quotes_list)


data


## Smater version : Auto detect Next Page
import requests
from bs4 import BeautifulSoup

url = "https://quotes.toscrape.com/"
all_quotes = []

while url:
    print("Scraping:", url)

    r = requests.get(url)
    soup = BeautifulSoup(r.text, "html.parser")

    quotes = soup.find_all("div", class_="quote")

    for q in quotes:
        text = q.find("span", class_="text").text
        author = q.find("small", class_="author").text
        all_quotes.append({
            "Quote": quote,
            "Author": author,
        })

    # find next page link
    next_btn = soup.find("li", class_="next")
    if next_btn:
        url = "https://quotes.toscrape.com" + next_btn.a["href"]
    else:
        url = None

print("Total quotes:", len(all_quotes))


data2 = pd.DataFrame(all_quotes)
                     


data2






